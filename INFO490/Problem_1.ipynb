{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "63892cd7525e56a0b9058ec5a4ace217",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 14 Problem 1\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "## Author: Radhir Kothuri\n",
    "### Primary Reviewer: Apurv Garg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c757acddadf9f30f9021ccbd0127adc0",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, April 30, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b6d1d520ee78f9604f006ece6d9526c",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "% matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats as sts\n",
    "import pymc3 as pm\n",
    "\n",
    "# testing tools\n",
    "from nose.tools import (\n",
    "    assert_equal, assert_true, assert_is_instance\n",
    ")\n",
    "\n",
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "# These two lines suppress warnings that sometimes\n",
    "# occur when making visualizations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "m_true = 0.7\n",
    "b_true = 0.3\n",
    "def theModel(xmin=0, xmax = 1, num=20):\n",
    "    np.random.seed(23)\n",
    "    sigma = 0.3\n",
    "    x = np.linspace(xmin, xmax, num)\n",
    "    y = b_true + m_true * x - sigma * np.random.randn(len(x))\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f6cda771735f955d2d4b6e8f3e6bad4",
     "grade": false,
     "grade_id": "cell-d60388a84c8fa3d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "In this question, we will be exploring alternative methods of model fitting for linear models that we have explored in previous weeks. Specifically, in the question below, you will use the `sts.linregress` (Week 1 material) and the `statsmodel.formula.api.smf.OLS` functions in order to determine which evaluation method yields more accurate parameters. We will define a model as being more accurate if it has a higher `r-value`.\n",
    "\n",
    "- Complete the function `get_model_params` that takes in 2 parameters: `x_vals` and `y_vals` that represent the `x` and `y` points respectively.\n",
    "- Return a 2-tuple of the maximum r-value after evaluating both approaches as well as either the string `ols` or `linregress` depending on which method returned the maximum r-value.\n",
    "- **Hint: Use the `rsquared` property after calling `fit()` when evaluating using ols method. You will need to take the square root of this in order to retrieve the actual r-value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9085b3bf78be988e968dc84fbdfbab40",
     "grade": false,
     "grade_id": "problem1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_model_params(x_vals, y_vals):\n",
    "    \"\"\"\n",
    "    Return the r-value of the approach that produces the maximum r-value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vals: a list of ints\n",
    "    y_vals: a list of ints\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    2-tuple of the maximum r-value followed by the string of the method that returned\n",
    "    the highest r-value\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE \n",
    "    \n",
    "    #using ols method\n",
    "    result_ols = smf.OLS(y_vals, x_vals).fit()\n",
    "    #obtain the rsquared value\n",
    "    import math\n",
    "    r_1 = math.sqrt(result_ols.rsquared)\n",
    "    \n",
    "    #using linregress method\n",
    "    slope, intercept, r_value, p_value, std_err = sts.linregress(x_vals, y_vals)\n",
    "    \n",
    "    #compare two methods\n",
    "    if r_1 < r_value:\n",
    "        result_r = r_value\n",
    "        result_method = \"linregress\"\n",
    "    else:\n",
    "        result_r = r_1\n",
    "        result_method = \"ols\"\n",
    "    \n",
    "    return (result_r, result_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3b00b58803673493e88a7a6fe7931b19",
     "grade": true,
     "grade_id": "problem1_test",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cases\n",
    "x_vals, y_vals = theModel(num=100)\n",
    "r_val, method = get_model_params(x_vals, y_vals)\n",
    "assert_equal(method, 'ols')\n",
    "assert_almost_equal(r_val, 0.8873103577785, decimal=4)\n",
    "\n",
    "x_vals, y_vals = theModel(num=2000)\n",
    "r_val, method = get_model_params(x_vals, y_vals)\n",
    "assert_equal(method, 'ols')\n",
    "assert_almost_equal(r_val, 0.891001337078, decimal=4)\n",
    "\n",
    "x_vals, y_vals = theModel(xmin=1, xmax=2000, num=2000)\n",
    "r_val, method = get_model_params(x_vals, y_vals)\n",
    "assert_equal(method, 'ols')\n",
    "assert_almost_equal(r_val, 0.999999721605, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbffeee0e3514a2e3c4c27fc9b44051a",
     "grade": false,
     "grade_id": "cell-544e70cc7b248111",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, we be using the `pymc3` library to create linear models and evaluate them using Bayesian Model Fitting using trace analysis.\n",
    "\n",
    "- Complete the function `linear_model` which returns the result of the trace analysis from the function.\n",
    "- Define a linear model `y = mx+b` where `m` is the slope of the function, and `b` is the y-intercept and where `x` and `y` are the respective input and output of the function.\n",
    "- `m` is normally distributed with a `mu` of 1 and a `std` of 1.0\n",
    "- `b` is uniformally distributed from 0 to 1\n",
    "- For observation errrors, define a stochastic variable, `sigma`, that is normally distributed with a `mu` of 1 and a `std` of 2.0\n",
    "- **Note: Please use `b`, `m`, `sigma` as the specific names for each of the distributions. This will be checked in the tests.**\n",
    "- Estimate the model paramters with the maximum a posteriori (MAP) method (using default parameters).\n",
    "- Use the No-U-Turn Sampler (NUTS) to generate posterior samples.\n",
    "- The function will take 4 parameters: `x_vals`, `y_vals`, `random_seed`, and `n_samples`\n",
    "- `random_seed` and `n_samples` should be used as parameters to the `sample()` function.\n",
    "- **Note: Validation might take a little longer for this assignment, so please be patient and please start early on this problem to not overload the course server the day before it's due.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e955ecd1f2111793db015643aa0d2bd9",
     "grade": false,
     "grade_id": "problem2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def linear_model(x_vals, y_vals, random_seed, n_samples):\n",
    "    '''    \n",
    "    Return the result of the trace analysis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_vals: A np.ndarray\n",
    "    y_vals: A np.ndarray\n",
    "    random_seed: An int\n",
    "    n_samples: An int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pm.backends.base.MultiTrace instance\n",
    "    '''\n",
    "    #please define intercept, slope, and sigma in that order \n",
    "    \n",
    "    with pm.Model() as linear_model:\n",
    "    \n",
    "        # First, define stohastic model variables\n",
    "        b = pm.Uniform('b', lower = 0, upper = 1)\n",
    "        m = pm.Normal('m', mu = 1.0, sd = 1.0)\n",
    "        \n",
    "        # Now define stochastic variable for observation errors.    \n",
    "        sigma = pm.Normal('sigma', mu = 1., sd = 2.0) #beta=10, testval=1.)\n",
    "\n",
    "        # Expected values using original indepedent variables\n",
    "        # Deterministic Variable\n",
    "        y_exp =  b + m * x_vals\n",
    "    \n",
    "        # Sample values (likelihood)\n",
    "        likelihood = pm.Normal('y', mu=y_exp, sd=sigma, observed=y_vals)\n",
    "    \n",
    "    \n",
    "        start = pm.find_MAP()\n",
    "        step = pm.NUTS(scaling=start)\n",
    "        trace = pm.sample(n_samples, step=step, start=start, random_seed=random_seed)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce06812550bd5173ba5e39338e0dd165",
     "grade": true,
     "grade_id": "problem2_test",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 424.411086\n",
      "         Iterations: 15\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:03<00:00, 642.12it/s]\n"
     ]
    }
   ],
   "source": [
    "x_vals, y_vals = theModel(num=2000)\n",
    "trace = linear_model(x_vals, y_vals, n_samples=2000, random_seed=23)\n",
    "assert_is_instance(trace, pm.backends.base.MultiTrace)\n",
    "assert_true('b' in trace.varnames)\n",
    "assert_true('m' in trace.varnames)\n",
    "assert_true('sigma' in trace.varnames)\n",
    "for v in trace.varnames:\n",
    "    assert_equal(len(trace[v]), 2000)\n",
    "assert_almost_equal(trace['b'][0], 0.328787056433, decimal = 4)\n",
    "assert_almost_equal(trace['m'][27], 0.703106549777, decimal=4)\n",
    "assert_almost_equal(trace['sigma'][1002], 0.297812937265, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
