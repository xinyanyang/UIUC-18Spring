{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b876e6abf0cb6e774a09eb969d61cb75",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 3 Problem 1\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1f89d7628ddb8ced1dd0d46093b2376b",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, February 5, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0673d6bb7cadb7bf6718be3240f90e79",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nose.tools import assert_equal, assert_true, assert_almost_equal\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_breast_cancer, load_boston\n",
    "# We do this to ignore several specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Dataset\n",
    "For this assignment we will be using the built-in dataset about breast cancer and the respective information on indivudal breast cancer cases. This dataset has 569 samples and a dimensionality size of 30. In this assignment, we will be using the various attributes and Logistic Regression in order to create a model that will predict whether the individual case is either malignant (harmful) or benign (non-harmful). Throughout the assignment, we will be improving our model from one that is very naïve to a more complicated one that accounts for all the attributes in the given dataset. \n",
    "\n",
    "The following code below imports the dataset as a pandas dataframe and previews a few sample data points. It also concatenates a column called classification which contains whether the record was determined to be a malignant or benign tumor. **Note: In this dataset, a malignant tumor has a value of 0 and a benign tumor has a value of 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f5e9c587c758d5931661898caae88f5e",
     "grade": false,
     "grade_id": "data_set",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension       ...        worst texture  worst perimeter  \\\n",
       "0                 0.07871       ...                17.33           184.60   \n",
       "1                 0.05667       ...                23.41           158.80   \n",
       "2                 0.05999       ...                25.53           152.50   \n",
       "3                 0.09744       ...                26.50            98.87   \n",
       "4                 0.05883       ...                16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "0                0.2654          0.4601                  0.11890   \n",
       "1                0.1860          0.2750                  0.08902   \n",
       "2                0.2430          0.3613                  0.08758   \n",
       "3                0.2575          0.6638                  0.17300   \n",
       "4                0.1625          0.2364                  0.07678   \n",
       "\n",
       "   classification  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NOTE: Make sure to load this data set before completing the assignment\n",
    "'''\n",
    "# Load in the dataset as a Pandas DataFrame\n",
    "data = load_breast_cancer()\n",
    "data_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Preview the first few lines\n",
    "data_df['classification'] = data.target\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "8e827bc6292243ed71a40e605fc79bbf",
     "grade": false,
     "grade_id": "train_split_test",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Separate the dataset into training and testing data using the `train_test_split` function.\n",
    "The testing and training data will be used in all the successive questions so make sure to finish this\n",
    "question before proceeding to the other questions.\n",
    "\n",
    "- Set the test size to 0.3\n",
    "- Set the random_state to 23\n",
    "- Use data_df_clean and labels variables below as parameters to the `train_test_split` function\n",
    "'''\n",
    "\n",
    "data_df_clean = data_df[data_df.columns[:-1]]\n",
    "labels = data.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_df_clean, labels,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Construct a Random Forest Classifier\n",
    "\n",
    "Complete the following function `get_rfc` that returns a random forest classifier from the breast cancer dataset. The function parameters are `n_estimators`, and `max_features`. You will need to create a random forest classifier based on the function parameters passed into the `get_rfc` function. Fit the classifier with the training data as well. **NOTE: you will need to set the random_state to 23 for the classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ef1c62582735cb0d51c505f20a817a57",
     "grade": false,
     "grade_id": "problem1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_rfc(n_es, max_fea):\n",
    "    '''\n",
    "    Return a Random Forest Classifier based on the function parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators: An integer\n",
    "    max_features: An integer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A RandomForestClassifier object for the input data\n",
    "    '''\n",
    "    rfc = RandomForestClassifier(n_estimators = n_es, \n",
    "                                 max_features = max_fea,\n",
    "                                 random_state = 23)\n",
    "    \n",
    "    #fit estimator to training data\n",
    "    rfc = rfc.fit(x_train, y_train)\n",
    "    \n",
    "    return rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4744b590c8572b71a4f91450f08550d7",
     "grade": true,
     "grade_id": "problem1_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rfc_model = get_rfc(10, 10)\n",
    "assert_true(isinstance(rfc_model, RandomForestClassifier))\n",
    "assert_equal(rfc_model.n_estimators, 10)\n",
    "assert_equal(rfc_model.max_features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Find the most accurate number of `max_features`\n",
    "\n",
    "In some scenarios, `auto` might not be the best value for the `max_features` parameter that would yield a model with the highest prediction accuracy. We want to find which integer subset of the features would generate the highest prediction accuracy. Our previous `get_rfc` function will help us in generating models based on a variable number of `max_features`.\n",
    "\n",
    "Complete the function `find_best_max_features` that takes in 2 parameters: `data_df` and `labels` that iterates from 1 to 30 (the length of the number of features in the dataset) and determines the number of `max_features` that would yield the highest prediction accuracy. Return a 2-tuple of `(number_of_features, max_accuracy)` that contains the number of features that yielded the highest predictive accuracy.\n",
    "\n",
    "In order to find the prediction accuracy for a model, you can use the `score()` method on the `RegressionClassifier` object by passing in the testing data as parameters into the score function. **You will need to multiply the return value by 100 and return the `max_accuracy` as a percent instead of a decimal.**\n",
    "\n",
    "**NOTE: For the `get_rfc` function call, use 10 as the value for the `n_estimators` parameter. The autograder will check that you have called `get_rfc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2d8e240faa20caccd3a09652e89dd328",
     "grade": false,
     "grade_id": "problem2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_max_features(x = data_df, y = labels):\n",
    "    '''\n",
    "    Return the highest predictive accuracy and the respective max_features\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number_of_features, max_accuracy: A 2-tuple of integer, float\n",
    "    '''\n",
    "    #define a new list for storing scores for different models\n",
    "    score_list = []\n",
    "    \n",
    "    for i in range(1, 30):\n",
    "        #build the random forest\n",
    "        rfc = get_rfc(10, i)\n",
    "        \n",
    "        #compute and display accuracy score\n",
    "        score = 100.0 * rfc.score(x_test, y_test)\n",
    "        score_list.append(score)\n",
    "        \n",
    "    #compare scores to select the one with maximum accuracy\n",
    "    max_accuracy = max(score_list)\n",
    "    number_of_features = score_list.index(max_accuracy) + 1\n",
    "    \n",
    "    return number_of_features, max_accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bafdb14cdc9cb8d1620b88884fd4db2a",
     "grade": true,
     "grade_id": "problem2_test",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(max_features, accuracy) = find_best_max_features()\n",
    "assert_true(accuracy > 90.0)\n",
    "assert_true(max_features >= 1 and max_features <= 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e809b052c1155dcf557320ba94ef88dd",
     "grade": true,
     "grade_id": "problem2_test_2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#used to test whether `get_rfc` has been used for solutions where it has been explicitly specified.\n",
    "\n",
    "orig_get_rfc = get_rfc\n",
    "del get_rfc\n",
    "\n",
    "    # test get_rfc\n",
    "try:\n",
    "    find_best_max_features()\n",
    "\n",
    "    # if an NameError is thrown, that means get_rfc has been used\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "    # if no error is thrown, that means get_rfc has not been used\n",
    "else:\n",
    "    raise AssertionError(\"get_rfc has not been used in find_best_max_features\")\n",
    "\n",
    "    # restore the original function\n",
    "finally:\n",
    "    get_rfc = orig_get_rfc\n",
    "    del orig_get_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Rank feature importance\n",
    "\n",
    "Complete the following function `rank_feature_names` that will return a list of 2-tuples of (`feature_name`, `feature_importance`) that is ranked from the most important feature to the least important. The function takes in one parameter `n_estimators` which will be the parameter to the `get_rfc` function call that will return the rfc model based on the `n_estimators` parameter and the `max_features` parameter which should be set to the length of the `feature_names` variable. **Hint: You can access the feature importances for a model by using the `feature_importances_` field of the RandomForestClassifier object**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c4c66a18641b3d87f4ef8db7a399e77d",
     "grade": false,
     "grade_id": "problem3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rank_feature_names(n_estimators):\n",
    "    '''\n",
    "    Return a list of 2-tuples of (feature_name, feature_importance) \n",
    "    that is ranked from the most important feature to least important\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators: An integer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of 2-tuples where each tuple is (string, double)\n",
    "    '''\n",
    "    \n",
    "    feature_names = data.feature_names\n",
    "    \n",
    "    #build the rfc model\n",
    "    rfc_model = get_rfc(n_estimators, len(feature_names))\n",
    "    \n",
    "    #get the feature importances   \n",
    "    sort_data = sorted(zip(feature_names, 100*(rfc_model.feature_importances_)), key=lambda x: x[1])\n",
    "    results = list(reversed(sort_data))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e77759b9fb89b6bd0c37eaafea848de8",
     "grade": true,
     "grade_id": "problem3_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rankings = rank_feature_names(10)\n",
    "assert_equal(len(rankings), 30)\n",
    "assert_equal(rankings[0][0], 'worst concave points')\n",
    "assert_almost_equal(rankings[0][1], 33.933, places=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
