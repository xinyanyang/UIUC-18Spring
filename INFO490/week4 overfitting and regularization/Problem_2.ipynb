{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "25053ccb661521068ea64ae454a90220",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 4 Problem 2\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says YOUR CODE HERE. Do not write your answer in anywhere else other than where it says YOUR CODE HERE. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select Kernel, and restart the kernel and run all cells (Restart & Run all).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select File → Save and CheckPoint)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to Dashboard → Assignments and click the Submit button. Your work is not submitted until you click Submit.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "7. If your code does not pass the unit tests, it will not pass the autograder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e78b65ebc50f4eff106090a896d51958",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, February 12, 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f9a1bb0e6932da9e797cec879a3087b1",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_index_equal\n",
    "from nose.tools import assert_false, assert_equal, assert_almost_equal, assert_true, assert_in, assert_is_not\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set global figure properties\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({'axes.titlesize' : 20,\n",
    "                     'axes.labelsize' : 18,\n",
    "                     'legend.fontsize': 16})\n",
    "\n",
    "# Set default seaborn plotting style\n",
    "sns.set_style('white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fad02fcc6762bc3430df7fe968ec7099",
     "grade": false,
     "grade_id": "dataset_info",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Breast Cancer Dataset\n",
    "\n",
    "We will be using the built-in dataset about breast cancer and the respective information on indivudal breast cancer cases. This dataset has 569 samples and a dimensionality size of 30. We will be using only the 1st 10 features in order to create a Gradient Boosting model that will predict whether the individual case is either malignant (harmful) or benign (non-harmful).\n",
    "\n",
    "The following code below imports the dataset as a pandas dataframe. It also concatenates a column called classification which contains whether the record was determined to be a malignant or benign tumor. Note: In this dataset, a malignant tumor has a value of 0 and a benign tumor has a value of 1.\n",
    "\n",
    "We will create 3 different models using different classification techniques and try to tune the models using Grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d42c0a4b4abc40ec64adcc5fcea3d0cd",
     "grade": false,
     "grade_id": "load_data",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    212\n",
      "1    357\n",
      "Name: target, dtype: int64\n",
      "Number of features: 10\n"
     ]
    }
   ],
   "source": [
    "# Load in the dataset as a Pandas DataFrame\n",
    "data = load_breast_cancer()\n",
    "cancer_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "cancer_data['target'] = data.target\n",
    "# View the label distribution\n",
    "print(cancer_data.target.value_counts(ascending=True))\n",
    "\n",
    "features = cancer_data[cancer_data.columns[:10]]\n",
    "labels = cancer_data.target\n",
    "# Count the number of features\n",
    "print(\"Number of features:\", len(features.columns))\n",
    "\n",
    "test_frac = 0.4\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                    test_size=test_frac, random_state=40)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0004877c979d5bda3d221175f1b2e67b",
     "grade": false,
     "grade_id": "problem1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Problem 1\n",
    "\n",
    "In the code cell below, we will create a k Nearest Neighbors model to classify the tumor as malignant or benign. We will use scaling before fitting the model as scaling can have a huge impact on the predictions in case of kNN. We will use 'skf' for purpose of cross validation. Earlier we used loops to create different models for different values of Nearest Neighbors. Here, we will try different values of Nearest Neighbors(k) to build the model using Grid Search.\n",
    "\n",
    "\n",
    "**Remember : You don't have to perform the search itself. Your function should return the GridSearchCV instance so that the hyperparameters can be passed to the function to actually perform the grid search for model building.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "edbb0eb2b02f52db8b8ccde2eb33d8a1",
     "grade": false,
     "grade_id": "problem1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def knn(k_vals):\n",
    "    '''\n",
    "    Perform scaling using StandardScaler and define a KNeighborsClassifier(Create pipeline of scaler and estimator)\n",
    "\n",
    "    Create a Grid Search cross validator(cv=skf) for the above where param_grid will be a dictionary containing \n",
    "    n_neighbors as hyperparameter and k_vals as values. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k_vals : range of nearest neighbors value passed as a numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Grid search cross validator instance which has the Pipeline, paramater grid containing neighbor values \n",
    "    and cross-validation = 'skf' as parameters.\n",
    "    '''\n",
    "    # Create pipeline of scaler and estimator\n",
    "    knnp = Pipeline([('ss', StandardScaler()),\n",
    "                     ('knn', neighbors.KNeighborsClassifier())])\n",
    "    \n",
    "    # Create a dictionary of hyperparameters and values\n",
    "    params = dict(knn__n_neighbors=k_vals)\n",
    "\n",
    "    # Create grid search cross validator\n",
    "    gse = GridSearchCV(estimator=knnp, param_grid=params, cv=skf)\n",
    "    \n",
    "    return gse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "90f6d018175e97d46bb9169752b5ae85",
     "grade": true,
     "grade_id": "problem1_tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "k_vals = np.arange(1,101,2)\n",
    "gse = knn(k_vals)\n",
    "gse.fit(X_train, y_train)\n",
    "assert_equal(isinstance(gse, GridSearchCV), True)\n",
    "best_score = float('%4.3f' % round(gse.best_score_, 3))\n",
    "assert_almost_equal(0.935, best_score, places = 3)\n",
    "test_score = float('%4.3f' % round(gse.score(X_test, y_test), 3))\n",
    "assert_almost_equal(0.934, test_score, places = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd88e5cba035777eddae20c2a3fc170a",
     "grade": false,
     "grade_id": "problem2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Problem 2\n",
    "\n",
    "In the code cell below, we will create a Decision Tree model to classify the tumor as malignant or benign. However, we will **not** use scaling before fitting the model. We will use 'skf' for purpose of cross validation. We will try different values of max_depth and max_features to build the model using Grid Search.\n",
    "\n",
    "**Note :** Since a Decision Tree doesn't take much time to build, we will try all the posibble combinations.\n",
    "\n",
    "**Remember : You don't have to perform the search itself . Your function should return the GridSearchCV instance so that the hyperparameters can be passed to the function to actually perform the grid search for model building.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f29c7093318305ba0c258d0c3d1712d0",
     "grade": false,
     "grade_id": "problem2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tree(depth, features):\n",
    "    '''\n",
    "    Create a Grid Search cross validator(cv=svf) for DecisionTreeClassifier with random_state=40.\n",
    "    The parameter grid will be multi-dimensional and will contain max_depth and max_features as hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    depth : range of max_depth values passed as a numpy array\n",
    "    features : range of max_features values passed as a numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Grid search cross validator instance for DecisionTreeClassifier\n",
    "    '''\n",
    "    #create decison tree estimator\n",
    "    dtc = DecisionTreeClassifier(random_state = 40)   \n",
    "    \n",
    "    # Create a dictionary of hyperparameters and values      \n",
    "    params = {'max_depth': depth,\n",
    "              'max_features': features}\n",
    " \n",
    "    # Create grid search cross validator\n",
    "    gse = GridSearchCV(estimator=dtc, param_grid=params, cv=skf)\n",
    "    \n",
    "    return gse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f013c1dfb76a1912d088b09417180f25",
     "grade": true,
     "grade_id": "problem2_tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "depth = np.arange(1,10)\n",
    "features = np.arange(1,10)\n",
    "\n",
    "gse = tree(depth, features)\n",
    "gse.fit(X_train, y_train)\n",
    "assert_equal(isinstance(gse,GridSearchCV), True)\n",
    "gbe = gse.best_estimator_\n",
    "assert_equal(isinstance(gbe,DecisionTreeClassifier), True)\n",
    "assert_equal(gse.best_estimator_.max_depth, 3)\n",
    "assert_equal(gse.best_estimator_.max_features, 6)\n",
    "best_score = float('%4.3f' % round(gse.best_score_, 3))\n",
    "assert_almost_equal(0.927, best_score, places = 3)\n",
    "test_score = float('%4.3f' % round(gse.score(X_test, y_test), 3))\n",
    "assert_almost_equal(0.921, test_score, places = 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "047d6f762c76dbd37a593bb592cf9515",
     "grade": false,
     "grade_id": "problem3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Problem 3\n",
    "\n",
    "In the code cell below, we will create a Gradient Boosting model to classify the tumor as malignant or benign. We will **not** use scaling before fitting the model. We will use 'skf' for purpose of cross validation. We will try different values of learning_rate, n_estimators and max_features to build the model using Grid Search. Since a Gradient Boosting involves mutiple iterations, trying all possible combinations can be computationally very expensive. Hence we will use a Randomized Grid Search cross validator.\n",
    "\n",
    "**Note :** Although we are using Randomized Grid Search, the code cell containing tests might take some time to execute.\n",
    "\n",
    "**Remember : You don't have to perform the search itself . Your function should return the RandomizedSearchCV instance so that the hyperparameters can be passed to the function to actually perform the grid search for model building.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1a2eb3a038e99a7f213d7d724783a2e0",
     "grade": false,
     "grade_id": "problem3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def GBM(learning_rate, n_estimators, max_features, sample):\n",
    "    '''\n",
    "    Create a Randomized Grid Search cross validator(cv=svf and random_state=40) for \n",
    "    GradientBoostingClassifier with random_state=40.\n",
    "    \n",
    "    The parameter grid will be multi-dimensional and will contain learning_rate, n_estimators \n",
    "    and max_features as hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : range of learning_rate values passed as a numpy array\n",
    "    n_estimators : range of n_estimators values passed as a numpy array\n",
    "    max_features : range of max_features values passed as a numpy array\n",
    "    sample : Number of parameter settings that are sampled\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Randomized Grid search cross validator instance for GradientBoostingClassifier\n",
    "    '''\n",
    "    gbtc = GradientBoostingClassifier(random_state=40)\n",
    "\n",
    "    # Create parameter grid, by using explicit dictionary\n",
    "    pd = {'learning_rate': learning_rate,\n",
    "          'n_estimators': n_estimators,\n",
    "          'max_features': max_features}\n",
    " \n",
    "    # Run randomized search\n",
    "    rscv = RandomizedSearchCV(gbtc, param_distributions=pd,\n",
    "                              n_iter=sample, random_state=40, cv=skf)\n",
    "    \n",
    "    return rscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4c098a6635d702d3371805664427ae7",
     "grade": true,
     "grade_id": "problem3_tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = np.arange(0.01,0.05,0.01)\n",
    "n_estimators = np.arange(200,401,100)\n",
    "max_features = np.arange(3,8,2)\n",
    "tgse = GBM(learning_rate, n_estimators, max_features, 10)\n",
    "tgse.fit(X_train, y_train)\n",
    "tgbe = tgse.best_estimator_\n",
    "best_score = float('%4.3f' % round(tgse.best_score_, 3))\n",
    "test_score = float('%4.3f' % round(tgse.score(X_test, y_test), 3))\n",
    "\n",
    "assert_equal(isinstance(tgbe, GradientBoostingClassifier), True)\n",
    "assert_equal(isinstance(tgse, RandomizedSearchCV), True)\n",
    "assert_almost_equal(0.938, best_score, places = 3)\n",
    "assert_almost_equal(0.956, test_score, places = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
