{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c46bb2f30daff8283ee90c9393036ade",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem 3\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "7. **If your code does not pass the unit tests, it will not pass the autograder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "443aa0aeddaedb7d457f924b9de7c21a",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, April 02, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4bd3eb5a31576ce7499b30bd1e0e709d",
     "grade": false,
     "grade_id": "author",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Author: Kelechi Ikegwu\n",
    "### Primary Reviewer:  John Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73017eda13b802669052172d6ec43ebc",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal, assert_true, assert_false, assert_almost_equal\n",
    "import numpy.testing as npt\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "#import gensim.downloader as api\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b8da3c121d9eae31be9a260c5ec96ef",
     "grade": false,
     "grade_id": "prob_3-1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 3.1\n",
    "Write a function called *get_path_similarity* that takes in two words and calculates their path similarity using the wordnet corpus. Recall  that words passed to wordnet have an ending indicated their part of speech. In this case, we will use words that are marked with *.n.01*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4c247b219324479fd2cead8afa8b0018",
     "grade": false,
     "grade_id": "prob_3-1-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_path_similarity(x,y):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    x: the first word\n",
    "    y: the second word\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    the path similarity between the two words\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    x = wn.synsets(x)[0]\n",
    "    y = wn.synsets(y)[0]\n",
    "    \n",
    "    si = wn.path_similarity(x, y)\n",
    "    \n",
    "    return si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a673208f73423bf827e56cec14ada0ef",
     "grade": true,
     "grade_id": "prob_3-1-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(get_path_similarity('dog','boy'),0.1428, 3)\n",
    "assert_almost_equal(get_path_similarity('dog','friend'),0.1666, 3)\n",
    "assert_almost_equal(get_path_similarity('drive','boy'),0.0833, 3)\n",
    "assert_almost_equal(get_path_similarity('man','boy'),0.3333, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f7d3d913af1d046c8899e372f9458fe9",
     "grade": false,
     "grade_id": "cell-508528f3ead5b773",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The cell below contains tweets that you will work with in Problem 3.2 & 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3a69e7574cd3f2ee5790ff0ace9f82a",
     "grade": false,
     "grade_id": "cell-b7dceb21f77ee077",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "twitter_data = [\n",
    "    \"I love when vendors start conversations with fictional problems that #DataScientist have.... For instance: The biggest problem data scientists have today is they have all these variables and don't know what's important. No.  That's not really a problem to figure out at all.\",\n",
    "    \"In honor of #IWD2018, I'm going to take some time over the next ~24 hours to recognize some of the brilliant women in tech / code / data science\",\n",
    "    'Ooohh! Among several other nice additions in the latest matplotlib release, there is now a new \"cividis\" colormap that \"should look effectively identical to colorblind and non-colorblind users.\" #Python #dataviz #DataScience',\n",
    "    'Google Makes Its #AI and #MachineLearning Courses Available to All via @Strat_AI - http://klou.tt/11oqiabgtf3si #ArtificialIntelligence #Analytics #BigData #DataScience #FinTech',\n",
    "    'Keras usage is most dominant in the industry (both large companies and startups) and in the overall data science community. In the research community, Keras has a much smaller market share',\n",
    "    '10 Most in demand #AI Skills are #ML #Python #R #DataScience #Hadoop #BigData #Java #DataMining #Spark #SAS  https://www.techrepublic.com/article/here-are-the-10-most-in-demand-ai-skills-and-how-to-develop-them/ … HT @TechRepublic @CyraIoT',\n",
    "    'Monsanto is working with an A.I. software startup to power its agricultural data science http://on.forbes.com/6018DTTyY',\n",
    "    '#InternetOfThings is transforming the way #enterprises, #governments and #consumers interact w/ the physical world... buy how does #IoT work?  #AI #SmartHome #Wearables #ConnectedCar #IIoT #Digital #BigData #DataAnalytics #DataScience #IoE @MikeQuindazzi via #PwC '\n",
    "    'Data-driven companies will be the winners in the digital economy. https://buff.ly/2ETCQo8  @Jabil #DataScience #businessintelligence #DigitalTransformation',\n",
    "    '13 applications for #ArtificialIntelligence in #Insurance. hashtags #AI #IoT #Insurtech #Fintech #BigData #DataScience link http://bit.ly/2F4trhN',\n",
    "    'This Is Who Controls Bitcoin https://www.forbes.com/sites/ktorpey/2018/02/28/this-is-who-controls-bitcoin/#5cda221f7bc9 … #blockchain #cryptocurrency #bitcoin #litecoin #neo #decentralizedblockchain #blockchains #Crypto #datascience #cryptocurrencynews #CryptocurrencyExchange #datascience #ethereum',\n",
    "    'How Millennials Are Using Cryptocurrency To Build The Future https://www.forbes.com/sites/laurencebradford/2018/02/26/how-millennials-are-using-cryptocurrency-to-build-the-future/#59e6f53d5c3a … #blockchain #cryptocurrency #bitcoin #litecoin #neo #decentralizedblockchain #blockchains #Crypto #datascience #cryptocurrencynews #CryptocurrencyExchange #datascience #ethereum',\n",
    "    '#AI Helps Identify People at Risk for Suicide https://www.wsj.com/articles/ai-helps-identify-people-at-risk-for-suicide-1519400853 … #DataScience #MachineLearning',\n",
    "    'By 2021, expenditures for #AI (#artificialintelligence automation) + #RPA (#robotic process #automation) expected to reach $4.9 billion. #BigData #DataMining #NLP #MachineLearning #DeepLearning #DataScience #Software @botscamp',\n",
    "    '7 More Steps to Mastering #MachineLearning With #Python | #ML #bigdata #analytics #AI #DL #datascience #datascientist @kdnuggets @ThePSF http://buff.ly/2EQ0mm5',\n",
    "    \"isn't data science fun!\",\n",
    "    \"What Is #MachineLearning As A Service (MLaaS)? #bigdata #IoT #technology #datascience #AI #BI\",\n",
    "    \"Los Angeles Teachers Give Students a Jump-Start on Data Science Careers\",\n",
    "    \"I'll be speaking about why you can’t do data science in a GUI at... \",\n",
    "    \"Learning to Trade with Reinforcement Learning | Open Data Science http://bit.ly/2EXwaFy  #MachineLearning #DataScience #reinforcementlearning #NeuralNetworks #ArtificialIntelligence #ai #stocks\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b6b6d35892a3acbf7bf0c2041b74d96",
     "grade": false,
     "grade_id": "prob32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 3.2 \n",
    "\n",
    "Complete the function *grab_tokens* by:\n",
    "\n",
    "1. reading in stop words from  a file. The path to the file is contained in the *stop_words_path* function parameter. [*HINT:* I'd recommend storing the words in a list to make the rest of the steps easier to work with.]\n",
    "2. Next convert the 2D list of the tweets *(that are in the function parameter data)* into a 2D list of the words. i.e [[\"This is a tweet\"]] --> [[\"this\", \"is\", \"a\", \"tweet\"]]. \n",
    "3. After this process use the results from item 1 to remove the stop words from item 2.\n",
    "4. Then create a new variable that contains words that appear at least 2 times from item 3. [*HINT*: You may find Counter from collections useful.]\n",
    "5. Return the results from item 3 and item 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "004c7718fbd3a134cdea4d3098733bb6",
     "grade": false,
     "grade_id": "prob32-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def grab_tokens(data, stop_words_path):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: list containing tweets about datascience\n",
    "    stop_words_path: path to file containing stop words.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    a nested list of list containing words that appear twice\n",
    "    a nested list of list containing all lowercase words with stop words removed\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    stop_words = list()\n",
    "    with open(stop_words_path,'r') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                stop_words.append(word)\n",
    "    \n",
    "    # Parse text into words, make lowercase and remove stop words\n",
    "    txts = [[word for word in sentance.lower().split() if word not in stop_words] for sentance in data]\n",
    "    \n",
    "    # Keep only those words appearing more than once\n",
    "    # Easy with a Counter, but need a flat list\n",
    "    frequency = Counter([word for txt in txts for word in txt])\n",
    "\n",
    "    # Now grab tokens that appear more than once\n",
    "    tokens = [[token for token in txt if frequency[token] > 1]\n",
    "              for txt in txts]\n",
    "    \n",
    "    return tokens, txts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92c7c2fe8e9c0062d1f38cf2abcb3304",
     "grade": false,
     "grade_id": "cell-c6e6da49fd5fc592",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokens, tweets2words = grab_tokens(twitter_data, '/home/data_scientist/data/misc/english.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e63262b8c6acc1d5cdd6d1df44aeab2",
     "grade": true,
     "grade_id": "prob3-2-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(tokens, [['#datascientist', 'problem', 'data', 'problem'], ['data', 'science'], ['#python', '#datascience'], ['#ai', '#machinelearning', 'via', '#artificialintelligence', '#analytics', '#bigdata', '#datascience', '#fintech'], ['keras', 'companies', 'data', 'science', 'keras'], ['#ai', '#ml', '#python', '#datascience', '#bigdata', '#datamining', '…'], ['data', 'science'], ['#iot', '#ai', '#bigdata', '#datascience', 'via', 'companies', '#datascience'], ['#artificialintelligence', '#ai', '#iot', '#fintech', '#bigdata', '#datascience'], ['…', '#blockchain', '#cryptocurrency', '#bitcoin', '#litecoin', '#neo', '#decentralizedblockchain', '#blockchains', '#crypto', '#datascience', '#cryptocurrencynews', '#cryptocurrencyexchange', '#datascience', '#ethereum'], ['…', '#blockchain', '#cryptocurrency', '#bitcoin', '#litecoin', '#neo', '#decentralizedblockchain', '#blockchains', '#crypto', '#datascience', '#cryptocurrencynews', '#cryptocurrencyexchange', '#datascience', '#ethereum'], ['#ai', '…', '#datascience', '#machinelearning'], ['#ai', '#bigdata', '#datamining', '#machinelearning', '#datascience'], ['#machinelearning', '#python', '#ml', '#bigdata', '#analytics', '#ai', '#datascience', '#datascientist'], ['data', 'science'], ['#machinelearning', '#bigdata', '#iot', '#datascience', '#ai'], ['data', 'science'], ['data', 'science'], ['learning', 'learning', 'data', 'science', '#machinelearning', '#datascience', '#artificialintelligence', '#ai']])\n",
    "\n",
    "assert_equal(tweets2words, [['love', 'vendors', 'start', 'conversations', 'fictional', 'problems', '#datascientist', 'have....', 'instance:', 'biggest', 'problem', 'data', 'scientists', 'today', 'variables', 'know', 'important.', 'no.', 'really', 'problem', 'figure', 'all.'], ['honor', '#iwd2018,', 'going', 'take', 'time', 'next', '~24', 'hours', 'recognize', 'brilliant', 'women', 'tech', 'code', 'data', 'science'], ['ooohh!', 'among', 'several', 'nice', 'additions', 'latest', 'matplotlib', 'release,', 'now', 'new', '\"cividis\"', 'colormap', '\"should', 'look', 'effectively', 'identical', 'colorblind', 'non-colorblind', 'users.\"', '#python', '#dataviz', '#datascience'], ['google', 'makes', '#ai', '#machinelearning', 'courses', 'available', 'via', '@strat_ai', '-', 'http://klou.tt/11oqiabgtf3si', '#artificialintelligence', '#analytics', '#bigdata', '#datascience', '#fintech'], ['keras', 'usage', 'dominant', 'industry', '(both', 'large', 'companies', 'startups)', 'overall', 'data', 'science', 'community.', 'research', 'community,', 'keras', 'much', 'smaller', 'market', 'share'], ['10', 'demand', '#ai', 'skills', '#ml', '#python', '#r', '#datascience', '#hadoop', '#bigdata', '#java', '#datamining', '#spark', '#sas', 'https://www.techrepublic.com/article/here-are-the-10-most-in-demand-ai-skills-and-how-to-develop-them/', '…', 'ht', '@techrepublic', '@cyraiot'], ['monsanto', 'working', 'a.i.', 'software', 'startup', 'power', 'agricultural', 'data', 'science', 'http://on.forbes.com/6018dttyy'], ['#internetofthings', 'transforming', 'way', '#enterprises,', '#governments', '#consumers', 'interact', 'w/', 'physical', 'world...', 'buy', '#iot', 'work?', '#ai', '#smarthome', '#wearables', '#connectedcar', '#iiot', '#digital', '#bigdata', '#dataanalytics', '#datascience', '#ioe', '@mikequindazzi', 'via', '#pwc', 'data-driven', 'companies', 'will', 'winners', 'digital', 'economy.', 'https://buff.ly/2etcqo8', '@jabil', '#datascience', '#businessintelligence', '#digitaltransformation'], ['13', 'applications', '#artificialintelligence', '#insurance.', 'hashtags', '#ai', '#iot', '#insurtech', '#fintech', '#bigdata', '#datascience', 'link', 'http://bit.ly/2f4trhn'], ['controls', 'bitcoin', 'https://www.forbes.com/sites/ktorpey/2018/02/28/this-is-who-controls-bitcoin/#5cda221f7bc9', '…', '#blockchain', '#cryptocurrency', '#bitcoin', '#litecoin', '#neo', '#decentralizedblockchain', '#blockchains', '#crypto', '#datascience', '#cryptocurrencynews', '#cryptocurrencyexchange', '#datascience', '#ethereum'], ['millennials', 'using', 'cryptocurrency', 'build', 'future', 'https://www.forbes.com/sites/laurencebradford/2018/02/26/how-millennials-are-using-cryptocurrency-to-build-the-future/#59e6f53d5c3a', '…', '#blockchain', '#cryptocurrency', '#bitcoin', '#litecoin', '#neo', '#decentralizedblockchain', '#blockchains', '#crypto', '#datascience', '#cryptocurrencynews', '#cryptocurrencyexchange', '#datascience', '#ethereum'], ['#ai', 'helps', 'identify', 'people', 'risk', 'suicide', 'https://www.wsj.com/articles/ai-helps-identify-people-at-risk-for-suicide-1519400853', '…', '#datascience', '#machinelearning'], ['2021,', 'expenditures', '#ai', '(#artificialintelligence', 'automation)', '+', '#rpa', '(#robotic', 'process', '#automation)', 'expected', 'reach', '$4.9', 'billion.', '#bigdata', '#datamining', '#nlp', '#machinelearning', '#deeplearning', '#datascience', '#software', '@botscamp'], ['7', 'steps', 'mastering', '#machinelearning', '#python', '#ml', '#bigdata', '#analytics', '#ai', '#dl', '#datascience', '#datascientist', '@kdnuggets', '@thepsf', 'http://buff.ly/2eq0mm5'], ['data', 'science', 'fun!'], ['#machinelearning', 'service', '(mlaas)?', '#bigdata', '#iot', '#technology', '#datascience', '#ai', '#bi'], ['los', 'angeles', 'teachers', 'give', 'students', 'jump-start', 'data', 'science', 'careers'], ['speaking', 'can’t', 'data', 'science', 'gui', 'at...'], ['learning', 'trade', 'reinforcement', 'learning', 'open', 'data', 'science', 'http://bit.ly/2exwafy', '#machinelearning', '#datascience', '#reinforcementlearning', '#neuralnetworks', '#artificialintelligence', '#ai', '#stocks']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6caf13576e72798c63e69c85818dbd7f",
     "grade": false,
     "grade_id": "prob3-3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### Problem 3.3 \n",
    "\n",
    "Complete the function *word2vec* by:\n",
    "- creating a [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) model with gensim.\n",
    "- Set the max distance between the current and predicted word within a sentence to be the *window* function paramater and ignore all words with a total frequency less than the *min_count* function parameter. \n",
    "- Return the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a7447719ca8a5ea1c4154e3463614866",
     "grade": false,
     "grade_id": "prob3-3-ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def word2vec(tweets2words, window, min_count):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    tweets2words: a nested list of list containing all lowercase words with stop words removed\n",
    "    window: The maximum distance between the current and predicted word within a sentence.\n",
    "    min_count:Ignores all words with total frequency lower than this.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Word2Vec Model of type (gensim.models.word2vec.Word2Vec)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    model = Word2Vec(tweets2words, window=window, min_count=min_count)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "386a4ff893879546ccae99891de3f096",
     "grade": true,
     "grade_id": "prob3-3-tests",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "model = word2vec(tweets2words, window=2, min_count=2)\n",
    "assert_true(isinstance(model, gensim.models.word2vec.Word2Vec))\n",
    "assert_equal(model.window, 2)\n",
    "assert_equal(model.min_count, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "910dee08b68e9be88dc66dfd5dfdd432",
     "grade": false,
     "grade_id": "cell-aabb148ba1cd38e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let us take a look at the 5 most similar words using the Word2Vec model you generated i Problem 3.3 for a few words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f9bd603ec5ea8ddf9c7f652932c8134b",
     "grade": false,
     "grade_id": "cell-b8a930d4ef8172b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar words for: data\n",
      "----------\n",
      "#ethereum 0.2322227656841278\n",
      "#ai 0.1937217116355896\n",
      "#blockchains 0.18409758806228638\n",
      "#analytics 0.18373388051986694\n",
      "#litecoin 0.16208364069461823\n",
      "\n",
      "\n",
      "Top 5 most similar words for: problem\n",
      "----------\n",
      "#litecoin 0.2830235958099365\n",
      "#analytics 0.27851247787475586\n",
      "#neo 0.23377743363380432\n",
      "#blockchains 0.20001503825187683\n",
      "#blockchain 0.19234278798103333\n"
     ]
    }
   ],
   "source": [
    "a = model.most_similar('data', topn=5)\n",
    "b = model.most_similar('problem', topn=5)\n",
    "\n",
    "print('Top 5 most similar words for: data')\n",
    "print('-'*10)\n",
    "for item in a:\n",
    "    print(item[0],  item[1])\n",
    "\n",
    "print('\\n')\n",
    "print('Top 5 most similar words for: problem')\n",
    "print('-'*10)\n",
    "for item in b:\n",
    "    print(item[0],  item[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
