{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2248c5b19ccd1eee07c7d7c76097b290",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem 4\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "7. **If your code does not pass the unit tests, it will not pass the autograder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "480673558ae7758c6ea248a6a7573eb0",
     "grade": false,
     "grade_id": "cell-f2a8814b67759c3a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Author: John Nguyen\n",
    "### Primary Reviewer: Kelechi Ikegwu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59c74d9eacad1d72d1fe9200211c050e",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, April 2, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a23c9681ade436070fd190c402edff8",
     "grade": false,
     "grade_id": "import_nose",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/data_scientist/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /home/data_scientist/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords, inaugural\n",
    "from nltk import pos_tag, FreqDist\n",
    "from nltk import sent_tokenize, word_tokenize, WhitespaceTokenizer, WordPunctTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal,\n",
    "    assert_is_instance,\n",
    "    assert_almost_equal,\n",
    "    assert_true\n",
    ")\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "# Download the stopwords\n",
    "nltk.download('stopwords');\n",
    "\n",
    "# Download inaugural address\n",
    "nltk.download('inaugural');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23b9b86958bf3d0a93ddf3f869d713f3",
     "grade": false,
     "grade_id": "cell-55f5152c9112ef90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this assignment, we will incorporate all of the NLP techniques you've learned from this week's notebooks in analyzing the [Inaugural Address Corpus documentation](http://www.nltk.org/book/ch02.html#inaugural-corpus) which contains a collection of 55 texts, one for each presidential address starting from 1789. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8cce4894b60f9a34c4a7a24e3847995e",
     "grade": false,
     "grade_id": "cell-c605871f65f61a12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt']\n"
     ]
    }
   ],
   "source": [
    "# View the number of files\n",
    "print(len(inaugural.fileids()))\n",
    "\n",
    "# View the list of files\n",
    "print(inaugural.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2bb7384ba395293f657113c9cffa29b",
     "grade": false,
     "grade_id": "cell-f8a521e9bd1854eb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fellow citizens, I am again called upon by the voice of my country to execute the functions of its Chief Magistrate. When the occasion proper for it shall arrive, I shall endeavor to express the high sense I entertain of this distinguished honor, and of the confidence which has been reposed in me by the people of united America.\\n\\nPrevious to the execution of any official act of the President the Constitution requires an oath of office. This oath I am now about to take, and in your presence: That if it shall be found during my administration of the Government I have in any instance violated willingly or knowingly the injunctions thereof, I may (besides incurring constitutional punishment) be subject to the upbraidings of all who are now witnesses of the present solemn ceremony.\\n\\n \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Washington's second inauguration address\n",
    "inaugural.raw('1793-Washington.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45953778e08b53f328766b9ee0ea475e",
     "grade": false,
     "grade_id": "prob1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Tokenizer\n",
    "\n",
    "Create the wrapper function _tokenizer()_ that tokenize an inputted string depending on the specific <i>token_type</i>:\n",
    "\n",
    "- \"sentence\": Tokenize by sentence.\n",
    "- \"word\": Tokenize by word.\n",
    "- \"whitespace\": Tokenize by whitespace.\n",
    "- \"wordpunctuation\": Tokenize by word and punctuation.\n",
    "\n",
    "Note, do not remove punctuation. Your function should output as a list of string. You may use any of the built-in functions in the [nltk.tokenize package](http://www.nltk.org/api/nltk.tokenize.html).\n",
    "\n",
    "__Example:__\n",
    "\n",
    "- _tokenizer(\"All your base belongs to us.\", \"sentence\")_ should return ['All your base belongs to us.']\n",
    "- _tokenizer(\"All your base belongs to us.\", \"word\")_ should return ['All', 'your', 'base', 'belongs', 'to', 'us', '.']\n",
    "- _tokenizer(\"All your base belongs to us.\", \"whitespace\")_ should return ['All', 'your', 'base', 'belongs', 'to', 'us.']\n",
    "- _tokenizer(\"All your base belongs to us.\", \"wordpunctuation\")_ should return ['All', 'your', 'base', 'belongs', 'to', 'us', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "759caacbdcad1ab61f19257c001c7aa3",
     "grade": false,
     "grade_id": "prob1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text, token_type):\n",
    "    '''\n",
    "    Converts text into tokens.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: a String.\n",
    "    token_type: a String specifying either a sentence, word, whitespace or word punctuation tokenizer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tokens: a List\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    if token_type == 'sentence' :\n",
    "        tokens = sent_tokenize(text)\n",
    "    elif token_type == 'word':\n",
    "        tokens = word_tokenize(text)\n",
    "    elif token_type == 'whitespace':\n",
    "        tokens = WhitespaceTokenizer().tokenize(text)\n",
    "    else:\n",
    "        tokens = WordPunctTokenizer().tokenize(text)\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ea627300c0a9737cda8dcef6c80fc63",
     "grade": true,
     "grade_id": "prob1_grade",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test1 = tokenizer(inaugural.raw('2001-Bush.txt'), \"wordpunctuation\")\n",
    "assert_equal(type(test1), list)\n",
    "assert_equal(len(test1), 1825)\n",
    "\n",
    "test2 = tokenizer(inaugural.raw('2001-Bush.txt'), \"sentence\")\n",
    "assert_equal(type(test2), list)\n",
    "assert_equal(len(test2), 97)\n",
    "\n",
    "test3 = tokenizer(inaugural.raw('1837-VanBuren.txt'), \"word\")\n",
    "assert_equal(type(test3), list)\n",
    "assert_equal(len(test3), 4160)\n",
    "\n",
    "test4 = tokenizer(inaugural.raw('1941-Roosevelt.txt'), \"whitespace\")\n",
    "assert_equal(type(test4), list)\n",
    "assert_equal(len(test4), 1360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c54fe7c4dbcf91040afa668b860fd3a2",
     "grade": false,
     "grade_id": "prob2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Part-of-Speech Tagging\n",
    "\n",
    "President Kennedy famously called Americans to take action and do more for their country in his inaugural address: _\"And so, my fellow Americans: ask not what your country can do for you—ask what you can do for your country.\"_ Let us determine which president have the most proportions of action words in their address.\n",
    "\n",
    "Create a function <i>proportion_action_words()</i> that takes tokens from a inaugural address and perform part-of-speech tagging. Of course, the length of addresses are all very different. As such, your function will output the total number of verbs over the number of tokens. Essentially, your function should do the following:\n",
    "\n",
    "- Use the built-in function <i>pos_tag()</i> with _tagset='universal'_ to do POS tagging.\n",
    "- <i>pos_tag()</i> will return a list of tuples. Iterate through the list and count the number of tags that is a \"VERB\".\n",
    "- Your function should return the proportion $\\frac{\\text{# of VERB}}{len(tokens)}$\n",
    "\n",
    "__Example:__ proportion_action_words(['ask', 'what', 'you', 'can', 'do', 'for', 'your', 'country', '.']) should return 0.3333."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ef4c91314525c5c4b3e9b57093ff0bb3",
     "grade": false,
     "grade_id": "prob2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def proportion_action_words(tokens):\n",
    "    '''\n",
    "    Compute proportion of verb.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: a list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result: a Float.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    tagged = pos_tag(tokens, tagset='universal')\n",
    "\n",
    "    a = list()\n",
    "    for item in tagged:\n",
    "        if item[1] == 'VERB':\n",
    "            a.append(item[0])\n",
    "    \n",
    "    result = len(a)/len(tagged)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "712b1a46035d3f10f8065a912e7d2599",
     "grade": true,
     "grade_id": "prob2_grade1",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test1 = tokenizer(inaugural.raw('1817-Monroe.txt'), \"word\")\n",
    "test1_verb_prop = proportion_action_words(test1)\n",
    "assert_equal(type(test1_verb_prop), float)\n",
    "assert_almost_equal(test1_verb_prop, 0.1655, 3)\n",
    "\n",
    "test2 = tokenizer(inaugural.raw('2009-Obama.txt'), \"word\")\n",
    "test2_verb_prop = proportion_action_words(test2)\n",
    "assert_equal(type(test2_verb_prop), float)\n",
    "assert_almost_equal(test2_verb_prop, 0.1744, 3)\n",
    "\n",
    "test3 = tokenizer(inaugural.raw('1789-Washington.txt'), \"word\")\n",
    "test3_verb_prop = proportion_action_words(test3)\n",
    "assert_equal(type(test3_verb_prop), float)\n",
    "assert_almost_equal(test3_verb_prop, 0.1600, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7932b3123656a8faaa5aaeb4a5ca714a",
     "grade": false,
     "grade_id": "cell-ec56b4b5d49e09df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Lets see which address had the highest proportion of verb. Does the result surprise you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d10a0623e558166d7c46bbae3de0a5e8",
     "grade": false,
     "grade_id": "cell-2fee45b16886bbd4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1865-Lincoln.txt', 0.19383825417201542),\n",
       " ('1793-Washington.txt', 0.1836734693877551),\n",
       " ('1989-Bush.txt', 0.1824600520252694),\n",
       " ('1869-Grant.txt', 0.18048780487804877),\n",
       " ('1969-Nixon.txt', 0.1762278167560875),\n",
       " ('1965-Johnson.txt', 0.17561260210035007),\n",
       " ('1913-Wilson.txt', 0.17541070482246954),\n",
       " ('1805-Jefferson.txt', 0.17506297229219145),\n",
       " ('2009-Obama.txt', 0.17444444444444446),\n",
       " ('1861-Lincoln.txt', 0.17254313578394598),\n",
       " ('1925-Coolidge.txt', 0.1725225225225225),\n",
       " ('1973-Nixon.txt', 0.17248255234297108),\n",
       " ('1981-Reagan.txt', 0.17175709665828243),\n",
       " ('1945-Roosevelt.txt', 0.17061611374407584),\n",
       " ('1977-Carter.txt', 0.17005813953488372),\n",
       " ('1821-Monroe.txt', 0.16908904810644831),\n",
       " ('1917-Wilson.txt', 0.16908212560386474),\n",
       " ('1937-Roosevelt.txt', 0.16725263686589653),\n",
       " ('1993-Clinton.txt', 0.1668472372697725),\n",
       " ('1921-Harding.txt', 0.16590726346823909),\n",
       " ('1873-Grant.txt', 0.16564833672776647),\n",
       " ('1817-Monroe.txt', 0.16557911908646003),\n",
       " ('1949-Truman.txt', 0.16526946107784432),\n",
       " ('1837-VanBuren.txt', 0.16490384615384615),\n",
       " ('2001-Bush.txt', 0.16363636363636364),\n",
       " ('1901-McKinley.txt', 0.16318163181631817),\n",
       " ('1985-Reagan.txt', 0.16301369863013698),\n",
       " ('1813-Madison.txt', 0.16129032258064516),\n",
       " ('1909-Taft.txt', 0.1602266872746007),\n",
       " ('1889-Harrison.txt', 0.16021164021164022),\n",
       " ('1933-Roosevelt.txt', 0.16011644832605532),\n",
       " ('1789-Washington.txt', 0.16005204944697463),\n",
       " ('1845-Polk.txt', 0.15940632228218968),\n",
       " ('1905-Roosevelt.txt', 0.15925925925925927),\n",
       " ('1881-Garfield.txt', 0.159190031152648),\n",
       " ('1961-Kennedy.txt', 0.15813350615683733),\n",
       " ('1849-Taylor.txt', 0.15534804753820033),\n",
       " ('1893-Cleveland.txt', 0.15463917525773196),\n",
       " ('1857-Buchanan.txt', 0.1539708265802269),\n",
       " ('1833-Jackson.txt', 0.15390686661404893),\n",
       " ('2005-Bush.txt', 0.15387949718248808),\n",
       " ('1841-Harrison.txt', 0.15212626041209995),\n",
       " ('1897-McKinley.txt', 0.15125086068395685),\n",
       " ('1941-Roosevelt.txt', 0.15072083879423329),\n",
       " ('1829-Jackson.txt', 0.15066225165562913),\n",
       " ('1853-Pierce.txt', 0.15059082165430063),\n",
       " ('1997-Clinton.txt', 0.14518760195758565),\n",
       " ('1801-Jefferson.txt', 0.14389610389610388),\n",
       " ('1957-Eisenhower.txt', 0.14255765199161424),\n",
       " ('1809-Madison.txt', 0.14115781126090404),\n",
       " ('1825-Adams.txt', 0.13754764930114358),\n",
       " ('1953-Eisenhower.txt', 0.13466424682395645),\n",
       " ('1929-Hoover.txt', 0.1339031339031339),\n",
       " ('1877-Hayes.txt', 0.13261913557443664),\n",
       " ('1885-Cleveland.txt', 0.1280923584387026),\n",
       " ('1797-Adams.txt', 0.1186966640806827)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which address have the highest proportion of verbs\n",
    "from operator import itemgetter\n",
    "\n",
    "call_to_action = []\n",
    "for address in inaugural.fileids():\n",
    "    address_tokens = tokenizer(inaugural.raw(address), \"word\")\n",
    "    address_verb_prop = proportion_action_words(address_tokens)\n",
    "    call_to_action.append((address, address_verb_prop))\n",
    "\n",
    "sorted(call_to_action, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35b10947f381b266163811e294119f88",
     "grade": false,
     "grade_id": "prob3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3: Word Frequency\n",
    "\n",
    "The function <i>frequent_tokens()</i> will take a document of tokens, remove the punctuation tokens (e.g, \".\", \"?\", etc.), compute the frequency distribution of each tokens and return the top n tokens. Your function must output a list of tuples.\n",
    "\n",
    "__Hint:__\n",
    "\n",
    "- You can use _string.punctuation_ which is a list punctuations. You can iterate and replace any tokens from the list that is a punctuation or use a one-line list comprehension. Refer to this week's notebook.\n",
    "- Use the _nltk_ built-in function _FreqDist()_ to compute the frequency count and <i>most_common()</i> to obtain the most frequent tokens. Refer to the following [documentation](http://www.nltk.org/api/nltk.html?highlight=freqdist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "89e27c91a380aff3ea5c61f1cd555dfc",
     "grade": false,
     "grade_id": "prob3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def frequent_tokens(tokens, n):\n",
    "    '''\n",
    "    Compute the token frequency distribution and return the top n token\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: a List of string.\n",
    "    n: a int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result: a List of tuples\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    new_mvr = []\n",
    "    new_mvr.extend([wtk for wtk in tokens if wtk not in string.punctuation])\n",
    "    fdist = FreqDist(new_mvr)\n",
    "    result = fdist.most_common(n)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8c873c958f4f89eb245b71c4e02a20c",
     "grade": true,
     "grade_id": "prob3_grade",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test1 = tokenizer(inaugural.raw('1817-Monroe.txt'), \"word\")\n",
    "test1_result = frequent_tokens(test1, 10)\n",
    "assert_equal(type(test1_result), list)\n",
    "assert_equal(type(test1_result[0]), tuple)\n",
    "assert_equal(test1_result, [('the', 264), ('of', 162), ('to', 120), ('and', 120),\n",
    "                                      ('in', 71), ('our', 60), ('a', 58), ('be', 50),\n",
    "                                      ('it', 45), ('is', 41)])\n",
    "\n",
    "test2 = tokenizer(inaugural.raw('1885-Cleveland.txt'), \"word\")\n",
    "test2_result = frequent_tokens(test2, 5)\n",
    "assert_equal(type(test2_result), list)\n",
    "assert_equal(type(test2_result[0]), tuple)\n",
    "assert_equal(test2_result, [('the', 167), ('of', 117), ('and', 102), ('to', 57), ('a', 29)])\n",
    "\n",
    "test3 = tokenizer(inaugural.raw('1957-Eisenhower.txt'), \"word\")\n",
    "test3_result = frequent_tokens(test3, 8)\n",
    "assert_equal(type(test3_result), list)\n",
    "assert_equal(type(test3_result[0]), tuple)\n",
    "assert_equal(test3_result, [('the', 106), ('of', 96), ('and', 50), ('to', 41),\n",
    "                            ('in', 39), ('we', 35), ('our', 35), ('all', 26)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "426e443bbd6b7a99c45cdce001996410",
     "grade": false,
     "grade_id": "cell-be6c83a414467315",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the token documents without the punctuation\n",
    "inaugural_docs = []\n",
    "\n",
    "for address in inaugural.fileids():\n",
    "    address_tokens = tokenizer(inaugural.raw(address), \"wordpunctuation\")\n",
    "    inaugural_docs.append([token for token in address_tokens if token not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "255d4147cb50ff5536b58cc0d36bd443",
     "grade": false,
     "grade_id": "prob4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Word2Vec\n",
    "\n",
    "The function <i>w2v_similarity()</i> will take a document of tokens, a string specifying a word and an integer. Your function should do the following:\n",
    "\n",
    "- Create a Word2Vec model for the documents with _size=10_, _window=5_, <i>min_count=3</i>, _seed=10_, _workers=1_.\n",
    "- Using the model, compute the Cosine similarity of the inputted word and output the top n similar words.\n",
    "\n",
    "__Note__: By default, [word2vec](https://radimrehurek.com/gensim/models/word2vec.html) is multi-threaded so setting the seed alone does not guarantee consistent result. The documentation recommend setting the workers to 1 to ensure consistency but this does not work in our current environment. Each time a kernel is started, a different hash is generated for the Word2Vec model. To guarantee the same similarity score, you need to set this hash explicitly. To avoid the trouble, we will not check the similarity score but make sure the model parameters are as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1ee83acd76f45267308c64e36ed45a2b",
     "grade": false,
     "grade_id": "prob4_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def w2v_similarity(documents, word, n):\n",
    "    '''\n",
    "    Create a Word2Vec model and compute the top n similar words to the input\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    documents: a list of list of tokens.\n",
    "    word: a String.\n",
    "    n: a int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scores: a List of tuples\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    model = Word2Vec(documents, size=10, window=5, min_count=3, seed=10, workers=1)\n",
    "    vals = model.most_similar(word, topn=n)\n",
    "    \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41707b08474fe5a79dcee4be727d22cc",
     "grade": true,
     "grade_id": "prob4_grade",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test1 = w2v_similarity(inaugural_docs, \"American\", 10)\n",
    "assert_equal(len(test1), 10)\n",
    "assert_equal(type(test1), list)\n",
    "assert_equal(type(test1[1]), tuple)\n",
    "assert_equal(type(test1[1][0]), str)\n",
    "assert_equal(type(test1[1][1]), float)\n",
    "assert_equal(type(test1[1][1]), float)\n",
    "assert_equal(test1[1][1] <= 1, True)\n",
    "assert_equal(test1[1][1] >= -1, True)\n",
    "\n",
    "\n",
    "test2 = w2v_similarity(inaugural_docs, \"citizen\", 200)\n",
    "assert_equal(len(test2), 200)\n",
    "assert_equal(type(test2), list)\n",
    "assert_equal(type(test2[101][0]), str)\n",
    "assert_equal(type(test2[101]), tuple)\n",
    "assert_equal(type(test2[101][1]), float)\n",
    "assert_equal(test2[101][1] <= 1, True)\n",
    "assert_equal(test2[101][1] >= -1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
