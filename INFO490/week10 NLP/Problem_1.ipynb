{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57acd9456b0c26fbfea2e2da5bf42712",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem 1\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "## Author: Radhir Kothuri\n",
    "### Primary Reviewer: Apurv Garg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59c74d9eacad1d72d1fe9200211c050e",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, April 2, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "db2d83b3f3cf1f5a95c43c31d73a2384",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.testing import assert_array_equal\n",
    "from nose.tools import assert_equal, assert_true, assert_almost_equal, assert_is_instance, assert_is_not\n",
    "import nltk, re\n",
    "from nltk import pos_tag\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "# We do this to ignore several specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f069fa694e1b0995f9945f80a2be93a",
     "grade": false,
     "grade_id": "cell-d60388a84c8fa3d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "In this question, we will be exploring collocations using `Bigrams` and the `Pointwise Mutual Information` algorithm in order to return the top `k` bi-grams in the inputted text data.\n",
    "\n",
    "- Finish the function `top_k` that takes in 2 parameters: `text_data`, a corpus of text data that is already tokenized, and `k`, an integer that represents the number of top k bigrams to return.\n",
    "- Compute the `k` most popular bigrams and return as a list of `2-tuples` where each element in the `2-tuple` is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca5786d713d4b84aa3c92ef62d3e5bf6",
     "grade": false,
     "grade_id": "problem1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_k(text_data, k):\n",
    "    '''    \n",
    "    Return the top k most popular bigrams\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_data: list of strings\n",
    "    k: An int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of 2-tuples where each element in 2-tuple is a string\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(text_data)\n",
    "    bgs = finder.nbest(bigram_measures.pmi, k)\n",
    "    \n",
    "    return bgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "823034b0e2b6adea9a7642ff285fc5d0",
     "grade": true,
     "grade_id": "problem1_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "top_k_bigrams = top_k(list(mvr.words()[:1000]), 6)\n",
    "assert_equal(len(top_k_bigrams), 6)\n",
    "for bigram in top_k_bigrams:\n",
    "    assert_true(type(bigram[0]) is str)\n",
    "    assert_true(type(bigram[1]) is str)\n",
    "assert_equal(top_k_bigrams[0], ('action', 'sequences'))\n",
    "assert_equal(top_k_bigrams[-1], ('baldwin', 'brother'))\n",
    "top_k_bigrams = top_k(list(mvr.words()[1000:2000]), 8)\n",
    "assert_equal(len(top_k_bigrams), 8)\n",
    "for bigram in top_k_bigrams:\n",
    "    assert_true(type(bigram[0]) is str)\n",
    "    assert_true(type(bigram[1]) is str)\n",
    "assert_equal(top_k_bigrams[0], ('20th', 'century'))\n",
    "assert_equal(top_k_bigrams[-1], ('big', 'pink'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a9fb83d2f23554b8d78cc27bd1d141a",
     "grade": false,
     "grade_id": "cell-544e70cc7b248111",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, we will explore part of speech tagging. Specifically, we will construct a function given a parameter `text_data` that will return all the values tagged with the input variable `classifier`.\n",
    "\n",
    "- Finish the function `get_part_of_speech` that takes in 2 variables `text_data`, a corpus of text data tokenized by white space, and `classifier`, a string that is one of the \n",
    "[12 `universal part of speech target` tags](http://www.nltk.org/book/ch05.html). See section 2.3.\n",
    "- With respect to this question however, we will only be passing in 'NOUN', 'VERB', or 'NUM' as the `classifier`.\n",
    "- Use Part of Speech Tagging in order to return a list of strings based on the `classifier` passed in. For example, after using part of speech tagging, if the classifier is `NOUN`, then iterate through all the tagged words and return a list of strings that are only `NOUN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "da87b195d889a82b1b48985bdb7a991c",
     "grade": false,
     "grade_id": "problem2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_part_of_speech(text_data, classifier):\n",
    "    '''    \n",
    "    Return a list of strings based on the value of `classifier`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_data: list of strings\n",
    "    classifier: A string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    tagged = pos_tag(text_data, tagset='universal')\n",
    "\n",
    "    a = list()\n",
    "    for item in tagged:\n",
    "        if item[1] == classifier:\n",
    "            a.append(item[0])\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7debf63ad0e0007b73db5d5585fa912",
     "grade": true,
     "grade_id": "problem2_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "all_numbers = get_part_of_speech(list(mvr.words()[:1000]), 'NUM')\n",
    "all_verbs = get_part_of_speech(list(mvr.words()[:1000]), 'VERB')\n",
    "assert_true('10' in all_numbers)\n",
    "for val in all_numbers:\n",
    "    assert_true(type(val) is str)\n",
    "    assert_true(val not in all_verbs)\n",
    "all_nouns = get_part_of_speech(list(mvr.words()[1000:2000]), 'NOUN')\n",
    "for val in all_nouns:\n",
    "    assert_true(type(val) is str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da0b9d8a3d4489de8c901e87ad7b4ea6",
     "grade": false,
     "grade_id": "cell-ef5687ed65f8cbfb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "In this question, we will be exploring tagged text extraction. We will be using regular expressions instead of a particular classifier variable in order to retrieve all the part of speeches that we want along with the specific counts of each part of speech.\n",
    "\n",
    "- Finish the function `get_tagged_text` that takes in the parameter `text_data`, a corpus of text data tokenized by white space. \n",
    "- The function will return 2 data structures:\n",
    "    - A list of strings that matches the part of speech that is either a plural noun (NNS), a proper noun (NNP), a past tense verb (VBD), or a foreign word (FW)\n",
    "    - A dictionary that maps each of the above part of speech tags to the respective counts that they appear in `text_data`. For example, if after the tagging stage there are 5 NNS, 4 NNP, and 3 VBD words. The dictionary should map `NNS`: 3, `NNP`: 4, and `VBD`: 3.\n",
    "    - Return the 2 data structures as a 2-tuple with the list of strings as the first element and the dictionary as the second element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dc4388afd26b858d4ffd5422909bb22e",
     "grade": false,
     "grade_id": "problem3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_tagged_text(text_data):\n",
    "    '''    \n",
    "    Use part of speech tagging with regular expressions in order \n",
    "    to return all words matching the particular regular expression as well as\n",
    "    a dictionary mapping the part of speech to the number of appearances in \n",
    "    text_data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_data: list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2-tuple of a list of strings and a dictionary\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ptgs = pos_tag(text_data)\n",
    "    \n",
    "    a = list()\n",
    "    for item in ptgs:\n",
    "         if item[1] in ['NNS', 'NNP', 'VBD', 'FW']:\n",
    "            a.append(item[1])\n",
    "\n",
    "    tc = Counter(a)\n",
    "    \n",
    "    return a, dict(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da4afe180043defa6a895f757984ecf9",
     "grade": true,
     "grade_id": "problem3_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "tagged_text, mapped_text = get_tagged_text(list(mvr.words()[:1000]))\n",
    "assert_true(type(tagged_text) is list)\n",
    "assert_true(type(mapped_text) is dict)\n",
    "for text in tagged_text:\n",
    "    assert_true(type(text) is str)\n",
    "for key in mapped_text:\n",
    "    assert_true(type(key) is str)\n",
    "    assert_true(type(mapped_text[key]) is int)\n",
    "for key in mapped_text.keys():\n",
    "    assert_true(key in ['NNS', 'NNP', 'VBD', 'FW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
